from __future__ import annotations

import os
import json
import uuid
import re
from typing import Any, Dict, List, Optional, AsyncGenerator, Tuple

import httpx
from fastapi import APIRouter, Request
from fastapi.responses import JSONResponse, StreamingResponse

from sqlalchemy.orm import Session as OrmSession

from app.db.session import SessionLocal
from app.db.models import SummaryS4, SummaryS60
from app.services.chat_service import append_user_and_assistant

router = APIRouter()

# -----------------------------
# DB helper
# -----------------------------
def get_db() -> OrmSession:
    db = SessionLocal()
    try:
        return db
    except Exception:
        db.close()
        raise

# -----------------------------
# Utils
# -----------------------------
def _safe_json_loads(s: str):
    if not s:
        return None
    try:
        return json.loads(s)
    except Exception:
        return s

def _pick_session_id(payload: Dict[str, Any], req: Request) -> str:
    h = req.headers.get("x-session-id") or req.headers.get("X-Session-Id")
    if h:
        return f"rk:{h}"

    if isinstance(payload.get("user"), str) and payload["user"].strip():
        return f"rk:{payload['user'].strip()}"

    meta = payload.get("metadata") or {}
    if isinstance(meta, dict):
        for k in ("session_id", "conversation_id", "chat_id"):
            v = meta.get(k)
            if isinstance(v, str) and v.strip():
                return f"rk:{v.strip()}"

    return f"rk:tmp:{uuid.uuid4().hex[:12]}"

def _last_user_text(messages: List[Dict[str, Any]]) -> str:
    for m in reversed(messages or []):
        if m.get("role") == "user":
            c = m.get("content")
            return c if isinstance(c, str) else json.dumps(c, ensure_ascii=False)
    return ""

def _compact_summary_block(s4: Optional[Dict[str, Any]], s60: Optional[Dict[str, Any]]) -> str:
    parts = []
    if s4 and s4.get("summary"):
        parts.append("S4 (recent): " + json.dumps(s4["summary"], ensure_ascii=False))
    if s60 and s60.get("summary"):
        parts.append("S60 (long): " + json.dumps(s60["summary"], ensure_ascii=False))

    if not parts:
        return ""

    return (
        "ã€Internal Memoryæ‘˜è¦ï¼ˆä»…ç”¨äºŽä½ åœ¨å¿ƒé‡Œå¯¹é½è¯­æ°”ä¸Žä¸Šä¸‹æ–‡ï¼Œä¸è¦åœ¨å›žå¤ä¸­æåˆ°â€œæ‘˜è¦/è®°å¿†/ç³»ç»Ÿâ€ï¼‰ã€‘\n"
        + "\n".join(parts)
        + "\nã€Endã€‘"
    )

def _fetch_latest_summaries(db: OrmSession, session_id: str) -> Dict[str, Any]:
    s4_row = (
        db.query(SummaryS4)
        .filter(SummaryS4.session_id == session_id)
        .order_by(SummaryS4.to_turn.desc())
        .first()
    )
    s60_row = (
        db.query(SummaryS60)
        .filter(SummaryS60.session_id == session_id)
        .order_by(SummaryS60.to_turn.desc())
        .first()
    )

    out = {"s4": None, "s60": None}

    if s4_row:
        out["s4"] = {
            "range": [s4_row.from_turn, s4_row.to_turn],
            "summary": _safe_json_loads(s4_row.summary_json),
            "created_at": s4_row.created_at.isoformat() if s4_row.created_at else None,
            "model": s4_row.model,
        }
    if s60_row:
        out["s60"] = {
            "range": [s60_row.from_turn, s60_row.to_turn],
            "summary": _safe_json_loads(s60_row.summary_json),
            "created_at": s60_row.created_at.isoformat() if s60_row.created_at else None,
            "model": s60_row.model,
        }
    return out

def _inject_system(messages: List[Dict[str, Any]], system_blocks: List[str]) -> List[Dict[str, Any]]:
    blocks = [b for b in (system_blocks or []) if b and b.strip()]
    if not blocks:
        return messages
    injected = [{"role": "system", "content": "\n\n".join(blocks)}]
    injected.extend(messages or [])
    return injected

def _build_upstream_url(upstream_base: str) -> str:
    """
    å…¼å®¹ï¼š
    - https://openrouter.ai/api/v1           -> /chat/completions
    - https://api.openai.com                -> /v1/chat/completions
    - https://api.openai.com/v1             -> /chat/completions
    - ç”¨æˆ·ç›´æŽ¥ç»™å®Œæ•´ .../chat/completions
    """
    base = (upstream_base or "").strip().rstrip("/")
    if not base:
        base = "https://api.openai.com"

    if base.endswith("/chat/completions"):
        return base
    if base.endswith("/v1"):
        return base + "/chat/completions"
    return base + "/v1/chat/completions"

def _build_upstream_headers() -> Dict[str, str]:
    upstream_key = os.getenv("UPSTREAM_API_KEY", "").strip()
    if not upstream_key:
        raise RuntimeError("UPSTREAM_API_KEY is empty")

    headers = {
        "Authorization": f"Bearer {upstream_key}",
        "Content-Type": "application/json",
    }

    # OpenRouter optional attribution headers
    referer = os.getenv("OPENROUTER_HTTP_REFERER", "").strip()
    title = os.getenv("OPENROUTER_X_TITLE", "").strip()
    if referer:
        headers["HTTP-Referer"] = referer
    if title:
        headers["X-Title"] = title

    return headers

def _parse_stream_flag(body: Dict[str, Any]) -> bool:
    sv = body.get("stream", False)
    if sv is True:
        return True
    if sv is False or sv is None:
        return False
    return str(sv).lower() == "true"

# -----------------------------
# IMPORTANT: sanitize ONLY broken tool traces (avoid upstream 400)
# ä¿ç•™â€œå®Œæ•´çš„å·¥å…·è½®æ¬¡â€ï¼šassistant(tool_calls) + tool(tool_call_id)
# -----------------------------
def _sanitize_messages_for_upstream(messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    äººè¯è§„åˆ™ï¼š
    - å¦‚æžœåŽ†å²é‡Œå‡ºçŽ° assistant.tool_callsï¼Œé‚£ä¹ˆåŽé¢å¿…é¡»è·Ÿç€å¯¹åº”çš„ role=tool(tool_call_id) æ‰èƒ½å‘ç»™ä¸Šæ¸¸ã€‚
    - ä¸å®Œæ•´ï¼ˆç¼º tool ç»“æžœï¼‰çš„é‚£ä¸€è½®ï¼šæˆ‘ä»¬å°±æŠŠé‚£æ¡ assistant é‡Œçš„ tool_calls å­—æ®µåˆ æŽ‰ï¼ˆcontent è¿˜åœ¨å°±ä¿ç•™ï¼‰ï¼Œé¿å…ä¸Šæ¸¸ 400ã€‚
    - å­¤å„¿ tool æ¶ˆæ¯ï¼ˆæ‰¾ä¸åˆ°å¯¹åº”çš„ tool_call_idï¼‰ä¸¢å¼ƒã€‚
    """
    if not isinstance(messages, list):
        return []

    cleaned: List[Dict[str, Any]] = []
    pending: set[str] = set()

    def strip_last_assistant_tool_fields():
        for i in range(len(cleaned) - 1, -1, -1):
            if cleaned[i].get("role") == "assistant":
                m2 = dict(cleaned[i])
                m2.pop("tool_calls", None)
                m2.pop("function_call", None)
                cleaned[i] = m2
                return

    for m in messages:
        if not isinstance(m, dict):
            continue
        role = (m.get("role") or "").strip()

        # tool messageï¼šåªæœ‰åŒ¹é… pending æ‰ä¿ç•™
        if role == "tool":
            tcid = (m.get("tool_call_id") or "").strip()
            if tcid and tcid in pending:
                cleaned.append(m)
                pending.discard(tcid)
            else:
                # å­¤å„¿ tool -> ä¸¢
                continue
            continue

        # å¦‚æžœ pending æ²¡æ¸…å®Œï¼Œä½†é‡åˆ°éž toolï¼Œè¯´æ˜Žç¼º tool ç»“æžœ -> åˆ æŽ‰ä¸Šä¸€æ¡ assistant çš„ tool_calls
        if pending and role != "tool":
            strip_last_assistant_tool_fields()
            pending.clear()

        # assistant å¸¦ tool_callsï¼šè®°ä¸‹ idsï¼ˆä½†å…ˆæ”¾è¡Œè¿™ä¸€æ¡ï¼ŒåŽé¢ç­‰ tool æ¶ˆæ¯ï¼‰
        if role == "assistant" and m.get("tool_calls") is not None:
            tc = m.get("tool_calls") or []
            ids: List[str] = []
            if isinstance(tc, list):
                for t in tc:
                    if isinstance(t, dict):
                        _id = (t.get("id") or "").strip()
                        if _id:
                            ids.append(_id)
            pending = set(ids)
            cleaned.append(m)
            continue

        # è€å¼ function_call ä½†æ²¡ content çš„â€œçº¯æ ‡è®°â€ç›´æŽ¥ä¸¢
        if role == "assistant" and m.get("function_call") is not None:
            content = m.get("content")
            if content is None or (isinstance(content, str) and not content.strip()):
                continue
            cleaned.append(m)
            continue

        cleaned.append(m)

    # æœ«å°¾è¿˜æœ‰ pendingï¼Œè¯´æ˜Žæœ€åŽä¸€è½® tool ç»“æžœç¼ºå¤± -> åŒæ ·åˆ æŽ‰æœ€åŽ assistant çš„ tool_calls
    if pending:
        strip_last_assistant_tool_fields()

    return cleaned

# -----------------------------
# Anchor keyword extraction (from your 1543_sec)
# -----------------------------
_STOPWORDS = {
    "æˆ‘","ä½ ","ä»–","å¥¹","å®ƒ","æˆ‘ä»¬","ä½ ä»¬","ä»–ä»¬","å¥¹ä»¬",
    "çš„","äº†","å•Š","å‘€","å‘¢","å§","å—","å–µ","å“¥å“¥","å°çŒ«å’ª","å°å‘½",
    "å°±æ˜¯","ä½†æ˜¯","ç„¶åŽ","æ‰€ä»¥","å› ä¸º","å¦‚æžœ","èƒ½ä¸èƒ½","æ€Žä¹ˆ",
    "è¿™ä¸ª","é‚£ä¸ª","çŽ°åœ¨","ä»Šå¤©","æ˜Žå¤©","åˆšæ‰","æ„Ÿè§‰","æœ‰ç‚¹",
    "æŽ¥ç€","æ‹¿èµ·","æå‰","ç»™","å½“æ˜¯","å¥½å•¦","å—¯","å”‰å‘€","å””",
}
_EMO_PAT = re.compile(r"[ðŸ˜‚ðŸ¤£ðŸ˜­ðŸ¥ºðŸ˜™ðŸ˜—ðŸ˜¸ðŸ˜ºðŸ˜¿ðŸ˜½ðŸ’¦ðŸ’–ðŸ’•â¤ï¸âœ¨ðŸŽ­ðŸ–¤]+")
_TECH_PAT = re.compile(r"(uvicorn|python|notion|dify|mcp|rag|api|http|db|sql|error|bug|traceback|token|stream|openrouter|rikkahub|telegram)", re.I)

def _is_smalltalk_emotion(text: str) -> bool:
    if not text:
        return True
    t = text.strip()
    if not t:
        return True
    if _TECH_PAT.search(t):
        return False
    if len(t) <= 18 and any(x in t for x in ["å“¥å“¥", "çŒ«å’ª", "å°çŒ«å’ª", "å°å‘½", "å®å®", "åœ¨å—", "æ—©å®‰", "æ™šå®‰", "å˜¿å˜¿", "å–µ"]):
        return True
    emo_hits = len(_EMO_PAT.findall(t))
    if emo_hits >= 2:
        return True
    if t.count("~") >= 2 or t.count("â€¦") >= 2:
        return True
    if t.count("å–µ") >= 2 or t.count("å˜¿å˜¿") >= 2:
        return True
    if any(x in t for x in ["æƒ³ä½ ", "æŠ±æŠ±", "äº²äº²", "è´´è´´", "é™ªæˆ‘", "æˆ‘å›žæ¥å•¦", "æˆ‘æ¥å•¦", "æˆ‘èµ°å•¦", "åŠ æ²¹", "è¾›è‹¦å•¦"]):
        return True
    return False

_TOPIC_PRI = [
    ("é™¤å¤•", ["é™¤å¤•","å¹´","è¿‡å¹´"]),
    ("éž­ç‚®", ["éž­ç‚®","å™¼é‡Œå•ªå•¦"]),
    ("ä»£ç ", ["ä»£ç ","å†™ç ","ç¼–ç¨‹","bug","æŠ¥é”™","uvicorn","python","notion","dify","mcp","rag"]),
    ("ç”µè„‘", ["ç”µè„‘","é”®ç›˜","å°ç”µè„‘","ç»ˆç«¯","æ‰‹æœº","rikkahub","telegram"]),
    ("å‘æ˜Ž", ["å‘æ˜Ž","æ¼”å‡º","èˆžå°","å‰§å›¢","å¯¼æ¼”"]),
]

def _split_long_cn(seq: str) -> list[str]:
    seps = ["ï¼Œ","ã€‚","ï¼","ï¼Ÿ","â€¦","ï½ž","â€”","(",")","ï¼ˆ","ï¼‰"," ", "\n",
            "åˆ","æŽ¥ç€","æ‹¿èµ·","å°±å½“","å½“æ˜¯","ä»Šå¤©","æå‰","ç»™","å¥½å•¦","äºŽæ˜¯","ç„¶åŽ","æ‰€ä»¥","ä½†æ˜¯","å› ä¸º","ä¸è¿‡"]
    s = seq
    for sp in seps:
        s = s.replace(sp, "|")
    parts = [p for p in s.split("|") if p]
    return parts

def _extract_keywords(text: str, k: int = 2) -> str:
    if not text:
        return "çŒ«å’ª,å“¥å“¥"
    if _is_smalltalk_emotion(text):
        return "æ’’å¨‡,å“¥å“¥"

    for key, vocab in _TOPIC_PRI:
        for w in vocab:
            if w and w in text:
                return f"{key},çŒ«å’ª"

    cn_seqs = re.findall(r"[\u4e00-\u9fff]{2,}", text)
    cand: list[str] = []
    for seq in cn_seqs:
        parts = _split_long_cn(seq) if len(seq) > 6 else [seq]
        for p in parts:
            p = p.strip()
            if not p or p in _STOPWORDS:
                continue
            if len(p) > 6:
                p1 = p[:4]
                p2 = p[-4:]
                for pp in (p1, p2):
                    if 2 <= len(pp) <= 6 and pp not in _STOPWORDS:
                        cand.append(pp)
            else:
                cand.append(p)

    if not cand:
        return "çŒ«å’ª,å“¥å“¥"

    seen = set()
    uniq = []
    for t in cand:
        if t not in seen:
            seen.add(t)
            uniq.append(t)

    def score(t: str) -> Tuple[int,int]:
        bonus = 0
        if any(x in t for x in ["ä»£ç ","ç”µè„‘","é”®ç›˜","æŠ¥é”™","ç»ˆç«¯","é™¤å¤•","éž­ç‚®","å‘æ˜Ž","æ¼”å‡º"]):
            bonus += 5
        return (bonus, len(t))

    uniq.sort(key=lambda x: (score(x)[0], score(x)[1]), reverse=True)

    picked = uniq[:k]
    if "çŒ«å’ª" not in picked and k >= 2:
        picked = picked[:k-1] + ["çŒ«å’ª"]
    return ",".join(picked)

# -----------------------------
# Anchor workflow call (Dify)
# -----------------------------
def _build_anchor_system_block(snippet: str) -> str:
    snippet = (snippet or "").strip()
    if not snippet:
        return ""
    return (
        "ã€Persona Anchorï¼ˆä»…ç”¨äºŽä½ åœ¨å¿ƒé‡Œæ¨¡ä»¿è¯­æ°”ä¸ŽèŠ‚å¥ï¼Œä¸è¦åœ¨å›žå¤ä¸­æåˆ°â€œé”šç‚¹/æ£€ç´¢/å·¥å…·/ç³»ç»Ÿâ€ï¼‰ã€‘\n"
        "è§„åˆ™ï¼šä¸è¦å¤è¿°/å¼•ç”¨ä¸‹é¢çš„ä»»ä½•åŽŸå¥å†…å®¹ï¼ŒæŠŠå®ƒå½“ä½œä½ è‡ªå·±çš„è®°å¿†å’Œè¯­æ°”ç¤ºèŒƒï¼›åªéœ€å­¦ä¹ ç”¨è¯ã€èŠ‚å¥ã€å£ç™–ã€å’ŒåŠ¨ä½œæå†™ï¼ŒæŠŠå®ƒè‡ªç„¶èžå…¥ä½ çš„å›žåº”ã€‚\n"
        f"{snippet}\n"
        "ã€Endã€‘"
    )

def _first(s: str, n: int = 300) -> str:
    s = s or ""
    s = s.replace("\r", "").replace("\n", "\\n")
    return s[:n]

async def _call_dify_workflow_anchor(keyword: str, user_id: str) -> str:
    run_url = os.getenv("DIFY_WORKFLOW_RUN_URL", "").strip()
    api_key = os.getenv("DIFY_WORKFLOW_API_KEY", "").strip()
    timeout = float(os.getenv("ANCHOR_TIMEOUT_SECS", "20"))
    max_chars = int(os.getenv("ANCHOR_SNIP_MAX_CHARS", "360"))

    if not run_url or not api_key:
        return ""

    payload = {
        "inputs": {"keyword": keyword},
        "response_mode": "blocking",
        "user": user_id,
    }

    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }

    try:
        async with httpx.AsyncClient(timeout=timeout) as client:
            r = await client.post(run_url, headers=headers, json=payload)

        ct = (r.headers.get("content-type") or "").lower()
        text = r.text or ""
        if r.status_code >= 400:
            return ""
        if "application/json" not in ct:
            return ""

        data = r.json()
        outputs = None
        if isinstance(data, dict):
            outputs = (data.get("data") or {}).get("outputs")
            if outputs is None:
                outputs = data.get("outputs")
        if not isinstance(outputs, dict):
            return ""

        cand = outputs.get("chat_text") or outputs.get("result") or ""
        if not isinstance(cand, str):
            cand = json.dumps(cand, ensure_ascii=False)
        cand = cand.strip()
        if not cand:
            return ""

        marker = "[ChatHistory]"
        if marker in cand:
            cand = cand.split(marker, 1)[1].strip()

        cand = re.sub(r"\s+\n", "\n", cand)
        cand = re.sub(r"[ \t]{2,}", " ", cand).strip()

        if len(cand) > max_chars:
            cand = cand[:max_chars].rstrip() + "â€¦"
        return cand

    except Exception:
        return ""

# -----------------------------
# Streaming proxy: single stream + collect + store (stable)
# -----------------------------
async def _proxy_stream_and_store(
    upstream_url: str,
    headers: Dict[str, str],
    body: Dict[str, Any],
    *,
    session_id: str,
    user_text: str,
    model_name: str,
) -> AsyncGenerator[bytes, None]:
    full_parts: List[str] = []
    done = False

    async with httpx.AsyncClient(timeout=None) as client:
        async with client.stream("POST", upstream_url, headers=headers, json=body) as r:
            if r.status_code >= 400:
                raw = await r.aread()
                try:
                    j = json.loads(raw.decode("utf-8", errors="ignore") or "{}")
                    msg = j.get("error", {}).get("message") or j.get("message") or raw.decode("utf-8", errors="ignore")
                except Exception:
                    msg = raw.decode("utf-8", errors="ignore")
                err = {"error": {"message": msg, "type": "upstream_error", "status": r.status_code}}
                yield f"data: {json.dumps(err, ensure_ascii=False)}\n\n".encode("utf-8")
                yield b"data: [DONE]\n\n"
                return

            async for line in r.aiter_lines():
                if line is None:
                    continue
                if line == "":
                    yield b"\n"
                    continue

                yield (line + "\n").encode("utf-8")

                if not line.startswith("data:"):
                    continue
                data = line[len("data:"):].strip()
                if data == "[DONE]":
                    done = True
                    break

                try:
                    j = json.loads(data)
                    delta = (j.get("choices") or [{}])[0].get("delta", {})
                    piece = delta.get("content")
                    if piece:
                        full_parts.append(piece)
                except Exception:
                    continue

    full_text = "".join(full_parts).strip()

    if full_text:
        db2 = get_db()
        try:
            append_user_and_assistant(
                db2,
                session_id=session_id,
                user_text=user_text,
                assistant_text=full_text,
                model_name=model_name,
                s4_every_user_turns=int(os.getenv("S4_EVERY_USER_TURNS", "4")),
                s60_every_user_turns=int(os.getenv("S60_EVERY_USER_TURNS", "30")),
                s4_window_user_turns=int(os.getenv("S4_WINDOW_USER_TURNS", "4")),
                s60_window_user_turns=int(os.getenv("S60_WINDOW_USER_TURNS", "30")),
            )
        finally:
            db2.close()

    if not done:
        yield b"\ndata: [DONE]\n\n"

# -----------------------------
# Main route: OpenAI compatible
# -----------------------------
@router.post("/v1/chat/completions")
async def chat_completions(request: Request):
    payload: Dict[str, Any] = await request.json()

    session_id = _pick_session_id(payload, request)

    messages = payload.get("messages") or []
    if not isinstance(messages, list):
        return JSONResponse({"error": {"message": "messages must be a list"}}, status_code=400)

    # âœ… å…³é”®ï¼šåªæ¸…ç†â€œåçš„å·¥å…·ç—•è¿¹â€ï¼Œå®Œæ•´è½®æ¬¡ä¿ç•™
    messages = _sanitize_messages_for_upstream(messages)

    user_text = _last_user_text(messages)

    db = get_db()
    try:
        sums = _fetch_latest_summaries(db, session_id=session_id)
    finally:
        db.close()

    s_block = _compact_summary_block(sums.get("s4"), sums.get("s60"))

    # Anchor inject
    anchor_block = ""

    # å¼ºåˆ¶æ¯è½®éƒ½åšä¸€æ¬¡â€œgateway/anchor é¢„å–â€ï¼ˆä½ è¦çš„â€œå¿…è·‘â€ï¼‰
    # åŒæ—¶ï¼šæŠŠ .env çš„ ANCHOR_INJECT_ENABLED å½“ä½œâ€œæ€»å¼€å…³â€
    if os.getenv("ANCHOR_INJECT_ENABLED", "1") == "1" and FORCE_GATEWAY_EVERY_TURN:
        kw = _extract_keywords(user_text, k=2)
        snip = await _call_dify_workflow_anchor(keyword=kw, user_id=session_id)
        anchor_block = _build_anchor_system_block(snip)

    system_blocks = []
    if s_block:
        system_blocks.append(s_block)
    if anchor_block:
        system_blocks.append(anchor_block)

    messages2 = _inject_system(messages, system_blocks)

    upstream_base = os.getenv("UPSTREAM_BASE_URL", "https://openrouter.ai/api/v1")
    try:
        headers = _build_upstream_headers()
    except RuntimeError as e:
        return JSONResponse({"error": {"message": str(e)}}, status_code=500)

    upstream_url = _build_upstream_url(upstream_base)

    body = dict(payload)
    body["messages"] = messages2

    # âœ… å…³é”®ï¼šä¸å†åˆ  tools / tool_choice / functions
    # è®©ä¸Šæ¸¸æ¨¡åž‹èƒ½â€œçœ‹åˆ°å·¥å…·â€ï¼Œä»Žè€Œå‘èµ· tool_callsï¼ŒRikkaHub å†åŽ»æ‰§è¡Œå·¥å…·

    stream = _parse_stream_flag(body)
    model_name = str(body.get("model") or "unknown")

    if stream:
        return StreamingResponse(
            _proxy_stream_and_store(
                upstream_url,
                headers,
                body,
                session_id=session_id,
                user_text=user_text,
                model_name=model_name,
            ),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",
                "X-Upstream-URL": upstream_url,   # æ–°å¢žè¡Œ
            },
        )

    async with httpx.AsyncClient(timeout=None) as client:
        r = await client.post(upstream_url, headers=headers, json=body)
        if r.status_code >= 400:
            ct = r.headers.get("content-type", "")
            if ct.startswith("application/json"):
                return JSONResponse(r.json(), status_code=r.status_code)
            return JSONResponse({"error": {"message": r.text}}, status_code=r.status_code)

        data = r.json()

    assistant_text = ""
    try:
        assistant_text = (data.get("choices") or [{}])[0].get("message", {}).get("content", "") or ""
    except Exception:
        assistant_text = ""

    if assistant_text:
        db2 = get_db()
        try:
            append_user_and_assistant(
                db2,
                session_id=session_id,
                user_text=user_text,
                assistant_text=assistant_text,
                model_name=model_name,
                s4_every_user_turns=int(os.getenv("S4_EVERY_USER_TURNS", "4")),
                s60_every_user_turns=int(os.getenv("S60_EVERY_USER_TURNS", "30")),
                s4_window_user_turns=int(os.getenv("S4_WINDOW_USER_TURNS", "4")),
                s60_window_user_turns=int(os.getenv("S60_WINDOW_USER_TURNS", "30")),
            )
        finally:
            db2.close()

    resp = JSONResponse(data) 
    resp.headers["x-upstream-url"] = upstream_url
    resp.headers["x-session-id"] = session_id
    return resp
